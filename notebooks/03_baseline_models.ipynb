{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 — Baseline models\n",
        "\n",
        "Ce notebook entraîne un premier baseline : **Logistic Regression (L2)**,\n",
        "puis exporte les métriques et la matrice de confusion dans `results/`."
      ],
      "id": "4d285727"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "project_root = Path.cwd().resolve()\n",
        "if not (project_root / \"src\").exists():\n",
        "    project_root = project_root.parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.data_loader import load_dataset\n",
        "from src.preprocessing import encode_labels, make_splits, scale_train_test\n",
        "from src.models import (\n",
        "    make_gradient_boosting,\n",
        "    make_linear_svm,\n",
        "    make_logreg_l1,\n",
        "    make_logreg_l2,\n",
        "    make_random_forest,\n",
        ")\n",
        "from src.evaluation import compute_metrics\n",
        "from src.visualization import save_figure\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "fig_dir = project_root / \"results\" / \"figures\"\n",
        "tables_dir = project_root / \"results\" / \"tables\"\n",
        "fig_dir.mkdir(parents=True, exist_ok=True)\n",
        "tables_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c11fbaef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ds = load_dataset(\n",
        "    data_path=str(project_root / \"data\" / \"raw\" / \"data.csv\"),\n",
        "    labels_path=str(project_root / \"data\" / \"raw\" / \"labels.csv\"),\n",
        ")\n",
        "\n",
        "X = ds.X\n",
        "y_enc, label_encoder = encode_labels(ds.y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = make_splits(X, y_enc, test_size=0.2, seed=42)\n",
        "X_train_scaled, X_test_scaled, scaler = scale_train_test(X_train, X_test)\n",
        "\n",
        "print(f\"Train shape: {X_train_scaled.shape} | Test shape: {X_test_scaled.shape}\")\n",
        "print(f\"Classes: {list(label_encoder.classes_)}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "46f32c44"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = make_logreg_l2(seed=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "metrics = compute_metrics(\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred,\n",
        "    labels=list(range(len(label_encoder.classes_))),\n",
        "    target_names=list(label_encoder.classes_),\n",
        ")\n",
        "\n",
        "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "print(f\"Macro F1: {metrics['macro_f1']:.4f}\")\n",
        "print(metrics[\"classification_report_text\"])"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c0489319"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "summary_df = pd.DataFrame(\n",
        "    [\n",
        "        {\n",
        "            \"model\": \"logreg_l2\",\n",
        "            \"accuracy\": metrics[\"accuracy\"],\n",
        "            \"macro_f1\": metrics[\"macro_f1\"],\n",
        "            \"n_train\": X_train_scaled.shape[0],\n",
        "            \"n_test\": X_test_scaled.shape[0],\n",
        "            \"n_features\": X_train_scaled.shape[1],\n",
        "            \"seed\": 42,\n",
        "            \"test_size\": 0.2,\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "summary_path = tables_dir / \"03_logreg_l2_metrics.csv\"\n",
        "summary_df.to_csv(summary_path, index=False)\n",
        "\n",
        "per_class_df = pd.DataFrame(metrics[\"per_class_report\"]).T\n",
        "per_class_path = tables_dir / \"03_logreg_l2_per_class_report.csv\"\n",
        "per_class_df.to_csv(per_class_path)\n",
        "\n",
        "print(f\"Saved: {summary_path}\")\n",
        "print(f\"Saved: {per_class_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4071e084"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(7, 6))\n",
        "cm_df = pd.DataFrame(\n",
        "    metrics[\"confusion_matrix\"],\n",
        "    index=label_encoder.classes_,\n",
        "    columns=label_encoder.classes_,\n",
        ")\n",
        "\n",
        "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
        "ax.set_title(\"Logistic Regression (L2) - Confusion Matrix\")\n",
        "ax.set_xlabel(\"Predicted label\")\n",
        "ax.set_ylabel(\"True label\")\n",
        "\n",
        "cm_path = fig_dir / \"03_logreg_l2_confusion_matrix.png\"\n",
        "save_figure(fig, str(cm_path))\n",
        "plt.show()\n",
        "print(f\"Saved: {cm_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d753777e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic Regression (L1) + feature selection\n",
        "\n",
        "On entraîne un modèle L1 (`solver=\"saga\"`) pour induire de la sparsité,\n",
        "puis on extrait les gènes sélectionnés (coefficients non nuls)."
      ],
      "id": "4de94079"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_l1 = make_logreg_l1(seed=42, c=1.0)\n",
        "model_l1.fit(X_train_scaled, y_train)\n",
        "y_pred_l1 = model_l1.predict(X_test_scaled)\n",
        "\n",
        "metrics_l1 = compute_metrics(\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred_l1,\n",
        "    labels=list(range(len(label_encoder.classes_))),\n",
        "    target_names=list(label_encoder.classes_),\n",
        ")\n",
        "\n",
        "print(f\"L1 Accuracy: {metrics_l1['accuracy']:.4f}\")\n",
        "print(f\"L1 Macro F1: {metrics_l1['macro_f1']:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "8a9640ba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "coef = model_l1.coef_  # shape: (n_classes, n_features)\n",
        "feature_names = np.array(X.columns)\n",
        "\n",
        "selected_mask = np.any(np.abs(coef) > 1e-12, axis=0)\n",
        "selected_indices = np.where(selected_mask)[0]\n",
        "\n",
        "max_abs_coef = np.max(np.abs(coef), axis=0)\n",
        "coef_df = pd.DataFrame({\n",
        "    \"gene\": feature_names,\n",
        "    \"selected\": selected_mask,\n",
        "    \"max_abs_coef\": max_abs_coef,\n",
        "})\n",
        "coef_df = coef_df.sort_values(\"max_abs_coef\", ascending=False)\n",
        "\n",
        "# Top 50 selected genes (global ranking across classes)\n",
        "top_genes_l1 = coef_df[coef_df[\"selected\"]].head(50).copy()\n",
        "top_genes_path = tables_dir / \"top_genes_l1.csv\"\n",
        "top_genes_l1.to_csv(top_genes_path, index=False)\n",
        "\n",
        "print(f\"Selected features: {int(selected_mask.sum())} / {coef.shape[1]}\")\n",
        "print(f\"Saved: {top_genes_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "8150a01f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_selected_total = int(selected_mask.sum())\n",
        "selected_per_class = (np.abs(coef) > 1e-12).sum(axis=1)\n",
        "\n",
        "plot_df = pd.DataFrame({\n",
        "    \"label\": [\"Total\"] + list(label_encoder.classes_),\n",
        "    \"n_selected\": [n_selected_total] + selected_per_class.tolist(),\n",
        "})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "sns.barplot(data=plot_df, x=\"label\", y=\"n_selected\", hue=\"label\", dodge=False, legend=False, ax=ax)\n",
        "ax.set_title(\"Number of features selected by L1 logistic regression\")\n",
        "ax.set_xlabel(\"Class (plus total)\")\n",
        "ax.set_ylabel(\"Number of selected features\")\n",
        "ax.tick_params(axis=\"x\", rotation=30)\n",
        "\n",
        "nb_features_plot_path = fig_dir / \"nb_features_selected.png\"\n",
        "save_figure(fig, str(nb_features_plot_path))\n",
        "plt.show()\n",
        "print(f\"Saved: {nb_features_plot_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "84f9edac"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparaison des baselines avec / sans PCA (95%)\n",
        "\n",
        "Cette section compare les performances de **LogReg (L2)** et **Linear SVM**\n",
        "sur les mêmes splits, avec features standardisées, puis après réduction PCA à 95% de variance."
      ],
      "id": "61ae29d9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pca_95 = PCA(n_components=0.95, random_state=42)\n",
        "X_train_pca = pca_95.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca_95.transform(X_test_scaled)\n",
        "\n",
        "model_factories = {\n",
        "    \"logreg_l2\": lambda: make_logreg_l2(seed=42),\n",
        "    \"linear_svm\": lambda: make_linear_svm(seed=42, c=1.0),\n",
        "}\n",
        "\n",
        "experiments = [\n",
        "    (\"without_pca\", X_train_scaled, X_test_scaled, X_train_scaled.shape[1]),\n",
        "    (\"with_pca_95\", X_train_pca, X_test_pca, X_train_pca.shape[1]),\n",
        "]\n",
        "\n",
        "rows = []\n",
        "for setting, Xtr, Xte, n_features_used in experiments:\n",
        "    for model_name, factory in model_factories.items():\n",
        "        model_i = factory()\n",
        "        model_i.fit(Xtr, y_train)\n",
        "        y_pred_i = model_i.predict(Xte)\n",
        "\n",
        "        m = compute_metrics(\n",
        "            y_true=y_test,\n",
        "            y_pred=y_pred_i,\n",
        "            labels=list(range(len(label_encoder.classes_))),\n",
        "            target_names=list(label_encoder.classes_),\n",
        "        )\n",
        "        rows.append(\n",
        "            {\n",
        "                \"model\": model_name,\n",
        "                \"setting\": setting,\n",
        "                \"accuracy\": m[\"accuracy\"],\n",
        "                \"macro_f1\": m[\"macro_f1\"],\n",
        "                \"n_features_used\": int(n_features_used),\n",
        "                \"seed\": 42,\n",
        "                \"test_size\": 0.2,\n",
        "            }\n",
        "        )\n",
        "\n",
        "comparison_df = pd.DataFrame(rows).sort_values([\"model\", \"setting\"]).reset_index(drop=True)\n",
        "comparison_path = tables_dir / \"baseline_with_without_pca.csv\"\n",
        "comparison_df.to_csv(comparison_path, index=False)\n",
        "\n",
        "print(comparison_df)\n",
        "print(f\"Saved: {comparison_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d7b03f69"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation croisée stratifiée (mean/std F1 macro)\n",
        "\n",
        "Pour une évaluation plus robuste (niveau labo), on utilise `StratifiedKFold`\n",
        "et on reporte la moyenne et l'écart-type du F1 macro."
      ],
      "id": "57cc07b2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_model_factories = {\n",
        "    \"logreg_l2\": lambda: make_logreg_l2(seed=42),\n",
        "    \"linear_svm\": lambda: make_linear_svm(seed=42, c=1.0),\n",
        "}\n",
        "\n",
        "cv_settings = [\"without_pca\", \"with_pca_95\"]\n",
        "cv_rows = []\n",
        "\n",
        "for model_name, factory in cv_model_factories.items():\n",
        "    for setting in cv_settings:\n",
        "        fold_f1 = []\n",
        "        for fold_idx, (train_idx, valid_idx) in enumerate(cv.split(X, y_enc), start=1):\n",
        "            X_fold_train = X.iloc[train_idx]\n",
        "            X_fold_valid = X.iloc[valid_idx]\n",
        "            y_fold_train = y_enc[train_idx]\n",
        "            y_fold_valid = y_enc[valid_idx]\n",
        "\n",
        "            scaler_cv = StandardScaler()\n",
        "            X_fold_train_scaled = scaler_cv.fit_transform(X_fold_train)\n",
        "            X_fold_valid_scaled = scaler_cv.transform(X_fold_valid)\n",
        "\n",
        "            if setting == \"with_pca_95\":\n",
        "                pca_cv = PCA(n_components=0.95, random_state=42)\n",
        "                X_fold_train_final = pca_cv.fit_transform(X_fold_train_scaled)\n",
        "                X_fold_valid_final = pca_cv.transform(X_fold_valid_scaled)\n",
        "                n_features_used = int(X_fold_train_final.shape[1])\n",
        "            else:\n",
        "                X_fold_train_final = X_fold_train_scaled\n",
        "                X_fold_valid_final = X_fold_valid_scaled\n",
        "                n_features_used = int(X_fold_train_final.shape[1])\n",
        "\n",
        "            model_cv = factory()\n",
        "            model_cv.fit(X_fold_train_final, y_fold_train)\n",
        "            y_fold_pred = model_cv.predict(X_fold_valid_final)\n",
        "\n",
        "            fold_macro_f1 = f1_score(y_fold_valid, y_fold_pred, average=\"macro\")\n",
        "            fold_f1.append(float(fold_macro_f1))\n",
        "\n",
        "        cv_rows.append(\n",
        "            {\n",
        "                \"model\": model_name,\n",
        "                \"setting\": setting,\n",
        "                \"cv_f1_macro_mean\": float(np.mean(fold_f1)),\n",
        "                \"cv_f1_macro_std\": float(np.std(fold_f1, ddof=1)),\n",
        "                \"n_splits\": 5,\n",
        "                \"seed\": 42,\n",
        "                \"n_features_used\": n_features_used,\n",
        "            }\n",
        "        )\n",
        "\n",
        "cv_results_df = pd.DataFrame(cv_rows).sort_values([\"model\", \"setting\"]).reset_index(drop=True)\n",
        "cv_results_path = tables_dir / \"cv_results.csv\"\n",
        "cv_results_df.to_csv(cv_results_path, index=False)\n",
        "\n",
        "print(cv_results_df)\n",
        "print(f\"Saved: {cv_results_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "b55ebbc2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Non-linear baselines (RF / Gradient Boosting)\n",
        "\n",
        "Cette section apporte une contribution non-linéaire explicite en comparant\n",
        "`Random Forest` et `Gradient Boosting` avec et sans standardisation."
      ],
      "id": "0b997f8a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "non_linear_factories = {\n",
        "    \"random_forest\": lambda: make_random_forest(seed=42, n_estimators=60),\n",
        "    \"gradient_boosting\": lambda: make_gradient_boosting(seed=42),\n",
        "}\n",
        "\n",
        "non_linear_experiments = [\n",
        "    (\"raw_features\", X_train, X_test),\n",
        "    (\"standardized_features\", X_train_scaled, X_test_scaled),\n",
        "]\n",
        "\n",
        "non_linear_rows = []\n",
        "for setting, Xtr, Xte in non_linear_experiments:\n",
        "    for model_name, factory in non_linear_factories.items():\n",
        "        model_nl = factory()\n",
        "        model_nl.fit(Xtr, y_train)\n",
        "        y_pred_nl = model_nl.predict(Xte)\n",
        "\n",
        "        m_nl = compute_metrics(\n",
        "            y_true=y_test,\n",
        "            y_pred=y_pred_nl,\n",
        "            labels=list(range(len(label_encoder.classes_))),\n",
        "            target_names=list(label_encoder.classes_),\n",
        "        )\n",
        "        non_linear_rows.append(\n",
        "            {\n",
        "                \"model\": model_name,\n",
        "                \"feature_setting\": setting,\n",
        "                \"accuracy\": m_nl[\"accuracy\"],\n",
        "                \"macro_f1\": m_nl[\"macro_f1\"],\n",
        "                \"n_features\": Xtr.shape[1],\n",
        "                \"seed\": 42,\n",
        "            }\n",
        "        )\n",
        "\n",
        "non_linear_df = pd.DataFrame(non_linear_rows).sort_values([\"model\", \"feature_setting\"]).reset_index(drop=True)\n",
        "non_linear_path = tables_dir / \"non_linear_baseline_comparison.csv\"\n",
        "non_linear_df.to_csv(non_linear_path, index=False)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "sns.barplot(data=non_linear_df, x=\"model\", y=\"macro_f1\", hue=\"feature_setting\", ax=ax)\n",
        "ax.set_title(\"Non-linear baseline comparison (macro F1)\")\n",
        "ax.set_xlabel(\"Model\")\n",
        "ax.set_ylabel(\"Macro F1\")\n",
        "plot_path = fig_dir / \"03_non_linear_baseline_comparison.png\"\n",
        "save_figure(fig, str(plot_path))\n",
        "plt.show()\n",
        "\n",
        "print(non_linear_df)\n",
        "print(f\"Saved: {non_linear_path}\")\n",
        "print(f\"Saved: {plot_path}\")"
      ],
      "id": "b6542f21",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}