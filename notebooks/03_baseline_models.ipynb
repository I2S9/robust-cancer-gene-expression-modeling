{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 — Baseline models\n",
        "\n",
        "Ce notebook entraîne un premier baseline : **Logistic Regression (L2)**,\n",
        "puis exporte les métriques et la matrice de confusion dans `results/`."
      ],
      "id": "4d285727"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "project_root = Path.cwd().resolve()\n",
        "if not (project_root / \"src\").exists():\n",
        "    project_root = project_root.parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.data_loader import load_dataset\n",
        "from src.preprocessing import encode_labels, make_splits, scale_train_test\n",
        "from src.models import make_logreg_l1, make_logreg_l2\n",
        "from src.evaluation import compute_metrics\n",
        "from src.visualization import save_figure\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "fig_dir = project_root / \"results\" / \"figures\"\n",
        "tables_dir = project_root / \"results\" / \"tables\"\n",
        "fig_dir.mkdir(parents=True, exist_ok=True)\n",
        "tables_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c11fbaef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ds = load_dataset(\n",
        "    data_path=str(project_root / \"data\" / \"raw\" / \"data.csv\"),\n",
        "    labels_path=str(project_root / \"data\" / \"raw\" / \"labels.csv\"),\n",
        ")\n",
        "\n",
        "X = ds.X\n",
        "y_enc, label_encoder = encode_labels(ds.y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = make_splits(X, y_enc, test_size=0.2, seed=42)\n",
        "X_train_scaled, X_test_scaled, scaler = scale_train_test(X_train, X_test)\n",
        "\n",
        "print(f\"Train shape: {X_train_scaled.shape} | Test shape: {X_test_scaled.shape}\")\n",
        "print(f\"Classes: {list(label_encoder.classes_)}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "46f32c44"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = make_logreg_l2(seed=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "metrics = compute_metrics(\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred,\n",
        "    labels=list(range(len(label_encoder.classes_))),\n",
        "    target_names=list(label_encoder.classes_),\n",
        ")\n",
        "\n",
        "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "print(f\"Macro F1: {metrics['macro_f1']:.4f}\")\n",
        "print(metrics[\"classification_report_text\"])"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c0489319"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "summary_df = pd.DataFrame(\n",
        "    [\n",
        "        {\n",
        "            \"model\": \"logreg_l2\",\n",
        "            \"accuracy\": metrics[\"accuracy\"],\n",
        "            \"macro_f1\": metrics[\"macro_f1\"],\n",
        "            \"n_train\": X_train_scaled.shape[0],\n",
        "            \"n_test\": X_test_scaled.shape[0],\n",
        "            \"n_features\": X_train_scaled.shape[1],\n",
        "            \"seed\": 42,\n",
        "            \"test_size\": 0.2,\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "summary_path = tables_dir / \"03_logreg_l2_metrics.csv\"\n",
        "summary_df.to_csv(summary_path, index=False)\n",
        "\n",
        "per_class_df = pd.DataFrame(metrics[\"per_class_report\"]).T\n",
        "per_class_path = tables_dir / \"03_logreg_l2_per_class_report.csv\"\n",
        "per_class_df.to_csv(per_class_path)\n",
        "\n",
        "print(f\"Saved: {summary_path}\")\n",
        "print(f\"Saved: {per_class_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4071e084"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(7, 6))\n",
        "cm_df = pd.DataFrame(\n",
        "    metrics[\"confusion_matrix\"],\n",
        "    index=label_encoder.classes_,\n",
        "    columns=label_encoder.classes_,\n",
        ")\n",
        "\n",
        "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
        "ax.set_title(\"Logistic Regression (L2) - Confusion Matrix\")\n",
        "ax.set_xlabel(\"Predicted label\")\n",
        "ax.set_ylabel(\"True label\")\n",
        "\n",
        "cm_path = fig_dir / \"03_logreg_l2_confusion_matrix.png\"\n",
        "save_figure(fig, str(cm_path))\n",
        "plt.show()\n",
        "print(f\"Saved: {cm_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d753777e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logistic Regression (L1) + feature selection\n",
        "\n",
        "On entraîne un modèle L1 (`solver=\"saga\"`) pour induire de la sparsité,\n",
        "puis on extrait les gènes sélectionnés (coefficients non nuls)."
      ],
      "id": "4de94079"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_l1 = make_logreg_l1(seed=42, c=1.0)\n",
        "model_l1.fit(X_train_scaled, y_train)\n",
        "y_pred_l1 = model_l1.predict(X_test_scaled)\n",
        "\n",
        "metrics_l1 = compute_metrics(\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred_l1,\n",
        "    labels=list(range(len(label_encoder.classes_))),\n",
        "    target_names=list(label_encoder.classes_),\n",
        ")\n",
        "\n",
        "print(f\"L1 Accuracy: {metrics_l1['accuracy']:.4f}\")\n",
        "print(f\"L1 Macro F1: {metrics_l1['macro_f1']:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "8a9640ba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "coef = model_l1.coef_  # shape: (n_classes, n_features)\n",
        "feature_names = np.array(X.columns)\n",
        "\n",
        "selected_mask = np.any(np.abs(coef) > 1e-12, axis=0)\n",
        "selected_indices = np.where(selected_mask)[0]\n",
        "\n",
        "max_abs_coef = np.max(np.abs(coef), axis=0)\n",
        "coef_df = pd.DataFrame({\n",
        "    \"gene\": feature_names,\n",
        "    \"selected\": selected_mask,\n",
        "    \"max_abs_coef\": max_abs_coef,\n",
        "})\n",
        "coef_df = coef_df.sort_values(\"max_abs_coef\", ascending=False)\n",
        "\n",
        "# Top 50 selected genes (global ranking across classes)\n",
        "top_genes_l1 = coef_df[coef_df[\"selected\"]].head(50).copy()\n",
        "top_genes_path = tables_dir / \"top_genes_l1.csv\"\n",
        "top_genes_l1.to_csv(top_genes_path, index=False)\n",
        "\n",
        "print(f\"Selected features: {int(selected_mask.sum())} / {coef.shape[1]}\")\n",
        "print(f\"Saved: {top_genes_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "8150a01f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_selected_total = int(selected_mask.sum())\n",
        "selected_per_class = (np.abs(coef) > 1e-12).sum(axis=1)\n",
        "\n",
        "plot_df = pd.DataFrame({\n",
        "    \"label\": [\"Total\"] + list(label_encoder.classes_),\n",
        "    \"n_selected\": [n_selected_total] + selected_per_class.tolist(),\n",
        "})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "sns.barplot(data=plot_df, x=\"label\", y=\"n_selected\", hue=\"label\", dodge=False, legend=False, ax=ax)\n",
        "ax.set_title(\"Number of features selected by L1 logistic regression\")\n",
        "ax.set_xlabel(\"Class (plus total)\")\n",
        "ax.set_ylabel(\"Number of selected features\")\n",
        "ax.tick_params(axis=\"x\", rotation=30)\n",
        "\n",
        "nb_features_plot_path = fig_dir / \"nb_features_selected.png\"\n",
        "save_figure(fig, str(nb_features_plot_path))\n",
        "plt.show()\n",
        "print(f\"Saved: {nb_features_plot_path}\")"
      ],
      "id": "84f9edac",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}