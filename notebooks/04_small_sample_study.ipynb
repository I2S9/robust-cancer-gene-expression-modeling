{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 — Small-sample study\n",
        "\n",
        "Étude de robustesse en faible effectif.\n",
        "\n",
        "- Tailles évaluées: `800`, `400`, `200`, `100`, `50`\n",
        "- Répétitions: 5 seeds\n",
        "- Modèles: `LogReg L1`, `Linear SVM`, `Random Forest`\n",
        "- Métriques suivies: `accuracy`, `macro F1`"
      ],
      "id": "e168b670"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "project_root = Path.cwd().resolve()\n",
        "if not (project_root / \"src\").exists():\n",
        "    project_root = project_root.parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.data_loader import load_dataset\n",
        "from src.evaluation import compute_metrics\n",
        "from src.models import make_linear_svm, make_logreg_l1, make_random_forest\n",
        "from src.preprocessing import encode_labels\n",
        "from src.visualization import save_figure\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "fig_dir = project_root / \"results\" / \"figures\"\n",
        "tables_dir = project_root / \"results\" / \"tables\"\n",
        "fig_dir.mkdir(parents=True, exist_ok=True)\n",
        "tables_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d57b6e51"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ds = load_dataset(\n",
        "    data_path=str(project_root / \"data\" / \"raw\" / \"data.csv\"),\n",
        "    labels_path=str(project_root / \"data\" / \"raw\" / \"labels.csv\"),\n",
        ")\n",
        "\n",
        "X = ds.X\n",
        "y_enc, label_encoder = encode_labels(ds.y)\n",
        "\n",
        "sample_sizes = [800, 400, 200, 100, 50]\n",
        "seeds = [0, 1, 2, 3, 4]\n",
        "\n",
        "def run_one_experiment(X_sub, y_sub, seed):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_sub,\n",
        "        y_sub,\n",
        "        test_size=0.2,\n",
        "        random_state=seed,\n",
        "        stratify=y_sub,\n",
        "    )\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    models = {\n",
        "        \"logreg_l1\": make_logreg_l1(seed=seed, c=1.0),\n",
        "        \"linear_svm\": make_linear_svm(seed=seed, c=1.0),\n",
        "        \"random_forest\": make_random_forest(seed=seed, n_estimators=60),\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "    for model_name, model in models.items():\n",
        "        if model_name == \"random_forest\":\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "        else:\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        metrics = compute_metrics(\n",
        "            y_true=y_test,\n",
        "            y_pred=y_pred,\n",
        "            labels=list(range(len(label_encoder.classes_))),\n",
        "            target_names=list(label_encoder.classes_),\n",
        "        )\n",
        "        rows.append(\n",
        "            {\n",
        "                \"model\": model_name,\n",
        "                \"accuracy\": metrics[\"accuracy\"],\n",
        "                \"macro_f1\": metrics[\"macro_f1\"],\n",
        "                \"n_train\": len(y_train),\n",
        "                \"n_test\": len(y_test),\n",
        "            }\n",
        "        )\n",
        "    return rows"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "37fe7196"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "all_rows = []\n",
        "n_classes = len(label_encoder.classes_)\n",
        "\n",
        "for n in sample_sizes:\n",
        "    n_eff = min(n, len(y_enc))\n",
        "    for seed in seeds:\n",
        "        if (len(y_enc) - n_eff) < n_classes:\n",
        "            X_sub = X\n",
        "            y_sub = y_enc\n",
        "        else:\n",
        "            X_sub, _, y_sub, _ = train_test_split(\n",
        "                X,\n",
        "                y_enc,\n",
        "                train_size=n_eff,\n",
        "                random_state=seed,\n",
        "                stratify=y_enc,\n",
        "            )\n",
        "\n",
        "        exp_rows = run_one_experiment(X_sub, y_sub, seed)\n",
        "        for r in exp_rows:\n",
        "            r.update({\"sample_size\": n_eff, \"seed\": seed})\n",
        "            all_rows.append(r)\n",
        "\n",
        "results_raw_df = pd.DataFrame(all_rows)\n",
        "summary_df = (\n",
        "    results_raw_df.groupby([\"model\", \"sample_size\"], as_index=False)\n",
        "    .agg(\n",
        "        accuracy_mean=(\"accuracy\", \"mean\"),\n",
        "        accuracy_std=(\"accuracy\", \"std\"),\n",
        "        macro_f1_mean=(\"macro_f1\", \"mean\"),\n",
        "        macro_f1_std=(\"macro_f1\", \"std\"),\n",
        "    )\n",
        "    .sort_values([\"model\", \"sample_size\"])\n",
        ")\n",
        "\n",
        "out_path = tables_dir / \"small_sample_results.csv\"\n",
        "summary_df.to_csv(out_path, index=False)\n",
        "\n",
        "print(summary_df)\n",
        "print(f\"Saved: {out_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "c07192ac"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(9, 5))\n",
        "sns.lineplot(\n",
        "    data=summary_df,\n",
        "    x=\"sample_size\",\n",
        "    y=\"macro_f1_mean\",\n",
        "    hue=\"model\",\n",
        "    marker=\"o\",\n",
        "    ax=ax,\n",
        ")\n",
        "ax.set_title(\"Performance vs sample size (macro F1 mean)\")\n",
        "ax.set_xlabel(\"Sample size\")\n",
        "ax.set_ylabel(\"Macro F1 (mean across seeds)\")\n",
        "ax.set_xticks(sample_sizes)\n",
        "\n",
        "perf_path = fig_dir / \"04_performance_vs_n.png\"\n",
        "save_figure(fig, str(perf_path))\n",
        "plt.show()\n",
        "print(f\"Saved: {perf_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a296f3ec"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(9, 5))\n",
        "sns.lineplot(\n",
        "    data=summary_df,\n",
        "    x=\"sample_size\",\n",
        "    y=\"macro_f1_std\",\n",
        "    hue=\"model\",\n",
        "    marker=\"o\",\n",
        "    ax=ax,\n",
        ")\n",
        "ax.set_title(\"Variance vs sample size (macro F1 std)\")\n",
        "ax.set_xlabel(\"Sample size\")\n",
        "ax.set_ylabel(\"Macro F1 (std across seeds)\")\n",
        "ax.set_xticks(sample_sizes)\n",
        "\n",
        "var_path = fig_dir / \"04_variance_vs_n.png\"\n",
        "save_figure(fig, str(var_path))\n",
        "plt.show()\n",
        "print(f\"Saved: {var_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "46a8319d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mini résumé\n",
        "\n",
        "- L'expérience small-sample est répétée sur 5 seeds pour réduire l'effet d'un split unique.\n",
        "- La courbe performance-vs-n met en évidence la dégradation quand la taille d'échantillon diminue.\n",
        "- La courbe variance-vs-n quantifie l'instabilité en faible effectif.\n",
        "- Les résultats agrégés sont sauvegardés dans `results/tables/small_sample_results.csv`."
      ],
      "id": "59917225"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}